{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "<font size=2>\n",
    "\n",
    "Random Forest is a popular machine learning algorithm used for classification tasks. It is an ensemble learning method that combines the predictions of multiple decision trees to make more accurate predictions.\n",
    "\n",
    "1. Building the forest:\n",
    "    \n",
    "The algorithm starts by creating an ensemble of decision trees. The number of trees is a user-defined parameter.\n",
    "\n",
    "2. Random feature selection:\n",
    "    \n",
    "At each node of every decision tree, a random subset of features is considered for splitting. This helps to introduce randomness and reduce the correlation between trees.\n",
    "\n",
    "3. Growing decision trees:\n",
    "    \n",
    "Each decision tree is grown by recursively partitioning the data based on the selected features. The splitting is done based on certain criteria, typically using measures like Gini impurity or entropy, to find the best feature and split point that maximizes the separation of classes.\n",
    "\n",
    "4. Voting for predictions:\n",
    "    \n",
    "Once all the decision trees are constructed, predictions are made by each tree individually. For classification, the class label that receives the majority of votes from the trees is chosen as the final prediction.\n",
    "\n",
    "<br>\n",
    "    \n",
    "Random Forest has several **advantages**:\n",
    "\n",
    "It is robust against overfitting because the randomness introduced during feature selection and tree construction helps to reduce variance.\n",
    "It can handle large datasets with a high number of features.\n",
    "It provides estimates of feature importance, allowing for insights into the relative significance of different features in the classification task.\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Code reference:\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=2, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=2, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0,0], [0,0,1], [0,1,0],\n",
    "              [20,20,20], [19,19,19],[20,21,18]])\n",
    "y = np.array([0, 0, 0,\n",
    "              1, 1, 1])\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[[0.98 0.02]\n",
      " [0.52 0.48]\n",
      " [0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[9,9,9],[10,10,10],[13,13,13]]))\n",
    "print(clf.predict_proba([[9,9,9],[10,10,10],[13,13,13]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from Captury Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest_Class():\n",
    "    \n",
    "    def __init__(self,Max_Depth,Random_State,Dataset_Path,Train_Len,Test_Len):\n",
    "        self.random_forest = RandomForestClassifier(max_depth=Max_Depth, random_state=Random_State)\n",
    "        self.get_data(dataset_path=Dataset_Path,train_len=Train_Len,test_len=Test_Len)\n",
    "\n",
    "    def get_data(self,dataset_path,train_len=10000,test_len=200):\n",
    "        # load data\n",
    "        x_data_path, y_data_path = dataset_path[0], dataset_path[1]\n",
    "        with open(x_data_path, 'rb') as xf:\n",
    "            x_data = np.load(xf)\n",
    "        with open(y_data_path, 'rb') as yf:\n",
    "            y_data = np.load(yf)\n",
    "        # define length for trainset and testset\n",
    "        self.Train_Len = train_len\n",
    "        self.Test_Len = test_len\n",
    "        # randomly select train samples\n",
    "        choices_train = np.random.randint(x_data.shape[0], size = self.Train_Len)\n",
    "        self.x_train = x_data[choices_train]\n",
    "        self.y_train = y_data[choices_train]\n",
    "        # delete train samples for test samples\n",
    "        new_x_data = np.delete(x_data, choices_train, axis=0)\n",
    "        new_y_data = np.delete(y_data, choices_train, axis=0)\n",
    "        print(f'x_train shape: {self.x_train.shape}')\n",
    "        print(f'y_train shape: {self.y_train.shape}')\n",
    "        # randomly select test samples\n",
    "        choices_test = np.random.randint(new_x_data.shape[0], size = self.Test_Len)\n",
    "        self.x_test = new_x_data[choices_test]\n",
    "        self.y_test = new_y_data[choices_test]\n",
    "        print(f'x_test shape: {self.x_test.shape}')\n",
    "        print(f'y_test shape: {self.y_test.shape}')\n",
    "        \n",
    "    def train(self):\n",
    "        self.random_forest.fit(self.x_train, self.y_train)\n",
    "        \n",
    "    def test(self):\n",
    "        self.P_pred = self.random_forest.predict_proba(self.x_test)\n",
    "        self.T_pred = self.random_forest.predict(self.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (10000, 38)\n",
      "y_train shape: (10000,)\n",
      "x_test shape: (100, 38)\n",
      "y_test shape: (100,)\n",
      "predicted target: [1 3 5 1 1 1 2 1 1 4 3 3 5 2 1 1 3 5 2 5 2 2 2 4 2 1 2 4 5 1 4 3 4 3 3 5 5\n",
      " 5 3 4 4 1 2 5 2 3 4 2 4 4 5 3 4 2 2 3 3 1 4 3 2 1 3 3 5 5 5 2 3 2 5 5 5 5\n",
      " 4 2 4 2 4 4 2 5 2 4 4 3 5 1 5 3 2 1 1 1 1 5 2 3 1 3]\n",
      "probability of predicted target: [[0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.69121922 0.13074736 0.09239423 0.04623163 0.03940757]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.1009976  0.27961624 0.48834451 0.06692933 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.69121922 0.13074736 0.09239423 0.04623163 0.03940757]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.41522699 0.28700789 0.0942655  0.05934317]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.16369396 0.41629853 0.27334562 0.0944017  0.0522602 ]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.05220151 0.08913764 0.06477123 0.79388962 0.        ]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.1009976  0.27961624 0.48834451 0.06692933 0.06411231]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.1009976  0.27961624 0.48834451 0.06692933 0.06411231]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.69121922 0.13074736 0.09239423 0.04623163 0.03940757]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.04820151 0.08913764 0.06477123 0.79788962 0.        ]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.66123296 0.14216081 0.10403638 0.05316228 0.03940757]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.04085881 0.05536596 0.06084999 0.         0.84292524]\n",
      " [0.14415645 0.42236188 0.27982944 0.09430906 0.05934317]\n",
      " [0.1009976  0.27961624 0.48834451 0.06692933 0.06411231]\n",
      " [0.68410819 0.13412026 0.095968   0.04624989 0.03955366]\n",
      " [0.1009976  0.27248135 0.49552297 0.06688577 0.06411231]]\n",
      "true target: [1 3 5 1 1 1 2 1 1 4 3 3 5 2 1 1 3 5 2 5 2 2 2 4 2 1 2 4 5 1 4 3 4 3 3 5 5\n",
      " 5 3 4 4 1 2 5 2 3 4 2 4 4 5 3 4 2 2 3 3 1 4 3 2 1 3 3 5 5 5 2 3 2 5 5 5 5\n",
      " 4 2 4 2 4 4 2 5 2 4 4 3 5 1 5 3 2 1 1 1 1 5 2 3 1 3]\n",
      "Are all predictions correct? True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    random_forest_cls = RandomForest_Class(Max_Depth=2,Random_State=0,\n",
    "                                           Dataset_Path=['x_data_UpperBody.npy','y_data_UpperBody.npy'],\n",
    "                                           Train_Len=10000,Test_Len=100)\n",
    "    random_forest_cls.train()\n",
    "    random_forest_cls.test()\n",
    "    print(f'predicted target: {random_forest_cls.T_pred}')\n",
    "    print(f'probability of predicted target: {random_forest_cls.P_pred}')\n",
    "    print(f'true target: {random_forest_cls.y_test}')\n",
    "    print(f'Are all predictions correct? {np.all(random_forest_cls.T_pred == random_forest_cls.y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaw",
   "language": "python",
   "name": "iaw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
